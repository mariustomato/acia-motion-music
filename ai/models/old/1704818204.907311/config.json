{"units": 128, "layers": 1, "activation": "tanh", "optimizer": "adam", "epochs": 25, "batch_size": 64, "loss": "mse"}